layer {
  name: "0"
  type: "Input"
  top: "0"
  input_param {
    shape {
      dim: 1
      dim: 3
      dim: 256
      dim: 256
    }
  }
}
layer {
  name: "205"
  type: "Convolution"
  bottom: "0"
  top: "205"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 3
    pad_w: 3
    kernel_h: 7
    kernel_w: 7
    stride_h: 2
    stride_w: 2
    dilation: 1
  }
}
layer {
  name: "206"
  type: "ReLU"
  bottom: "205"
  top: "206"
}
layer {
  name: "207"
  type: "Convolution"
  bottom: "206"
  top: "207"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "208"
  type: "ReLU"
  bottom: "207"
  top: "208"
}
layer {
  name: "209"
  type: "Convolution"
  bottom: "208"
  top: "209"
  convolution_param {
    num_output: 64
    bias_term: true
    group: 64
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "210"
  type: "ReLU"
  bottom: "209"
  top: "210"
}
layer {
  name: "211"
  type: "Convolution"
  bottom: "210"
  top: "211"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "212"
  type: "Convolution"
  bottom: "206"
  top: "212"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "213"
  type: "Eltwise"
  bottom: "211"
  bottom: "212"
  top: "213"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "214"
  type: "ReLU"
  bottom: "213"
  top: "214"
}
layer {
  name: "215"
  type: "Pooling"
  bottom: "214"
  top: "215"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "216"
  type: "Convolution"
  bottom: "215"
  top: "216"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "217"
  type: "ReLU"
  bottom: "216"
  top: "217"
}
layer {
  name: "218"
  type: "Convolution"
  bottom: "217"
  top: "218"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "219"
  type: "ReLU"
  bottom: "218"
  top: "219"
}
layer {
  name: "220"
  type: "Convolution"
  bottom: "219"
  top: "220"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "221"
  type: "Convolution"
  bottom: "215"
  top: "221"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "222"
  type: "Eltwise"
  bottom: "220"
  bottom: "221"
  top: "222"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "223"
  type: "ReLU"
  bottom: "222"
  top: "223"
}
layer {
  name: "224"
  type: "Convolution"
  bottom: "223"
  top: "224"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "225"
  type: "ReLU"
  bottom: "224"
  top: "225"
}
layer {
  name: "226"
  type: "Convolution"
  bottom: "225"
  top: "226"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "227"
  type: "ReLU"
  bottom: "226"
  top: "227"
}
layer {
  name: "228"
  type: "Convolution"
  bottom: "227"
  top: "228"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "229"
  type: "Eltwise"
  bottom: "228"
  bottom: "223"
  top: "229"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "230"
  type: "ReLU"
  bottom: "229"
  top: "230"
}
layer {
  name: "231"
  type: "Convolution"
  bottom: "230"
  top: "231"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "232"
  type: "ReLU"
  bottom: "231"
  top: "232"
}
layer {
  name: "233"
  type: "Convolution"
  bottom: "232"
  top: "233"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "234"
  type: "ReLU"
  bottom: "233"
  top: "234"
}
layer {
  name: "235"
  type: "Convolution"
  bottom: "234"
  top: "235"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "236"
  type: "Eltwise"
  bottom: "235"
  bottom: "230"
  top: "236"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "237"
  type: "ReLU"
  bottom: "236"
  top: "237"
}
layer {
  name: "238"
  type: "Pooling"
  bottom: "230"
  top: "238"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "239"
  type: "Convolution"
  bottom: "238"
  top: "239"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "240"
  type: "ReLU"
  bottom: "239"
  top: "240"
}
layer {
  name: "241"
  type: "Convolution"
  bottom: "240"
  top: "241"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "242"
  type: "ReLU"
  bottom: "241"
  top: "242"
}
layer {
  name: "243"
  type: "Convolution"
  bottom: "242"
  top: "243"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "244"
  type: "Eltwise"
  bottom: "243"
  bottom: "238"
  top: "244"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "245"
  type: "ReLU"
  bottom: "244"
  top: "245"
}
layer {
  name: "246"
  type: "Convolution"
  bottom: "245"
  top: "246"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "247"
  type: "ReLU"
  bottom: "246"
  top: "247"
}
layer {
  name: "248"
  type: "Convolution"
  bottom: "247"
  top: "248"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "249"
  type: "ReLU"
  bottom: "248"
  top: "249"
}
layer {
  name: "250"
  type: "Convolution"
  bottom: "249"
  top: "250"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "251"
  type: "Eltwise"
  bottom: "250"
  bottom: "245"
  top: "251"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "252"
  type: "ReLU"
  bottom: "251"
  top: "252"
}
layer {
  name: "253"
  type: "Pooling"
  bottom: "245"
  top: "253"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "254"
  type: "Convolution"
  bottom: "253"
  top: "254"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "255"
  type: "ReLU"
  bottom: "254"
  top: "255"
}
layer {
  name: "256"
  type: "Convolution"
  bottom: "255"
  top: "256"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "257"
  type: "ReLU"
  bottom: "256"
  top: "257"
}
layer {
  name: "258"
  type: "Convolution"
  bottom: "257"
  top: "258"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "259"
  type: "Eltwise"
  bottom: "258"
  bottom: "253"
  top: "259"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "260"
  type: "ReLU"
  bottom: "259"
  top: "260"
}
layer {
  name: "261"
  type: "Convolution"
  bottom: "260"
  top: "261"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "262"
  type: "ReLU"
  bottom: "261"
  top: "262"
}
layer {
  name: "263"
  type: "Convolution"
  bottom: "262"
  top: "263"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "264"
  type: "ReLU"
  bottom: "263"
  top: "264"
}
layer {
  name: "265"
  type: "Convolution"
  bottom: "264"
  top: "265"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "266"
  type: "Eltwise"
  bottom: "265"
  bottom: "260"
  top: "266"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "267"
  type: "ReLU"
  bottom: "266"
  top: "267"
}
layer {
  name: "268"
  type: "Pooling"
  bottom: "260"
  top: "268"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "269"
  type: "Convolution"
  bottom: "268"
  top: "269"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "270"
  type: "ReLU"
  bottom: "269"
  top: "270"
}
layer {
  name: "271"
  type: "Convolution"
  bottom: "270"
  top: "271"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "272"
  type: "ReLU"
  bottom: "271"
  top: "272"
}
layer {
  name: "273"
  type: "Convolution"
  bottom: "272"
  top: "273"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "274"
  type: "Eltwise"
  bottom: "273"
  bottom: "268"
  top: "274"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "275"
  type: "ReLU"
  bottom: "274"
  top: "275"
}
layer {
  name: "276"
  type: "Convolution"
  bottom: "275"
  top: "276"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "277"
  type: "ReLU"
  bottom: "276"
  top: "277"
}
layer {
  name: "278"
  type: "Convolution"
  bottom: "277"
  top: "278"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "279"
  type: "ReLU"
  bottom: "278"
  top: "279"
}
layer {
  name: "280"
  type: "Convolution"
  bottom: "279"
  top: "280"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "281"
  type: "Eltwise"
  bottom: "280"
  bottom: "275"
  top: "281"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "282"
  type: "ReLU"
  bottom: "281"
  top: "282"
}
layer {
  name: "283"
  type: "Pooling"
  bottom: "275"
  top: "283"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "284"
  type: "Convolution"
  bottom: "283"
  top: "284"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "285"
  type: "ReLU"
  bottom: "284"
  top: "285"
}
layer {
  name: "286"
  type: "Convolution"
  bottom: "285"
  top: "286"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "287"
  type: "ReLU"
  bottom: "286"
  top: "287"
}
layer {
  name: "288"
  type: "Convolution"
  bottom: "287"
  top: "288"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "289"
  type: "Eltwise"
  bottom: "288"
  bottom: "283"
  top: "289"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "290"
  type: "ReLU"
  bottom: "289"
  top: "290"
}
layer {
  name: "291"
  type: "Convolution"
  bottom: "290"
  top: "291"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "292"
  type: "ReLU"
  bottom: "291"
  top: "292"
}
layer {
  name: "293"
  type: "Convolution"
  bottom: "292"
  top: "293"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "294"
  type: "ReLU"
  bottom: "293"
  top: "294"
}
layer {
  name: "295"
  type: "Convolution"
  bottom: "294"
  top: "295"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "296"
  type: "Eltwise"
  bottom: "295"
  bottom: "290"
  top: "296"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "297"
  type: "ReLU"
  bottom: "296"
  top: "297"
}
layer {
  name: "298"
  type: "Convolution"
  bottom: "297"
  top: "298"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "299"
  type: "ReLU"
  bottom: "298"
  top: "299"
}
layer {
  name: "300"
  type: "Convolution"
  bottom: "299"
  top: "300"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "301"
  type: "ReLU"
  bottom: "300"
  top: "301"
}
layer {
  name: "302"
  type: "Convolution"
  bottom: "301"
  top: "302"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "303"
  type: "Eltwise"
  bottom: "302"
  bottom: "297"
  top: "303"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "304"
  type: "ReLU"
  bottom: "303"
  top: "304"
}
layer {
  name: "306"
  type: "Deconvolution"
  bottom: "304"
  top: "306"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 2
    group: 256
    stride: 2
  }
}
layer {
  name: "307"
  type: "Eltwise"
  bottom: "282"
  bottom: "306"
  top: "307"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "308"
  type: "Convolution"
  bottom: "307"
  top: "308"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "309"
  type: "ReLU"
  bottom: "308"
  top: "309"
}
layer {
  name: "310"
  type: "Convolution"
  bottom: "309"
  top: "310"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "311"
  type: "ReLU"
  bottom: "310"
  top: "311"
}
layer {
  name: "312"
  type: "Convolution"
  bottom: "311"
  top: "312"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "313"
  type: "Eltwise"
  bottom: "312"
  bottom: "307"
  top: "313"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "314"
  type: "ReLU"
  bottom: "313"
  top: "314"
}
layer {
  name: "316"
  type: "Deconvolution"
  bottom: "314"
  top: "316"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 2
    group: 256
    stride: 2
  }
}
layer {
  name: "317"
  type: "Eltwise"
  bottom: "267"
  bottom: "316"
  top: "317"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "318"
  type: "Convolution"
  bottom: "317"
  top: "318"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "319"
  type: "ReLU"
  bottom: "318"
  top: "319"
}
layer {
  name: "320"
  type: "Convolution"
  bottom: "319"
  top: "320"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "321"
  type: "ReLU"
  bottom: "320"
  top: "321"
}
layer {
  name: "322"
  type: "Convolution"
  bottom: "321"
  top: "322"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "323"
  type: "Eltwise"
  bottom: "322"
  bottom: "317"
  top: "323"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "324"
  type: "ReLU"
  bottom: "323"
  top: "324"
}
layer {
  name: "326"
  type: "Deconvolution"
  bottom: "324"
  top: "326"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 2
    group: 256
    stride: 2
  }
}
layer {
  name: "327"
  type: "Eltwise"
  bottom: "252"
  bottom: "326"
  top: "327"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "328"
  type: "Convolution"
  bottom: "327"
  top: "328"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "329"
  type: "ReLU"
  bottom: "328"
  top: "329"
}
layer {
  name: "330"
  type: "Convolution"
  bottom: "329"
  top: "330"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "331"
  type: "ReLU"
  bottom: "330"
  top: "331"
}
layer {
  name: "332"
  type: "Convolution"
  bottom: "331"
  top: "332"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "333"
  type: "Eltwise"
  bottom: "332"
  bottom: "327"
  top: "333"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "334"
  type: "ReLU"
  bottom: "333"
  top: "334"
}
layer {
  name: "336"
  type: "Deconvolution"
  bottom: "334"
  top: "336"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 2
    group: 256
    stride: 2
  }
}
layer {
  name: "337"
  type: "Eltwise"
  bottom: "237"
  bottom: "336"
  top: "337"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "338"
  type: "Convolution"
  bottom: "337"
  top: "338"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "339"
  type: "ReLU"
  bottom: "338"
  top: "339"
}
layer {
  name: "340"
  type: "Convolution"
  bottom: "339"
  top: "340"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "341"
  type: "ReLU"
  bottom: "340"
  top: "341"
}
layer {
  name: "342"
  type: "Convolution"
  bottom: "341"
  top: "342"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "343"
  type: "Eltwise"
  bottom: "342"
  bottom: "337"
  top: "343"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "344"
  type: "ReLU"
  bottom: "343"
  top: "344"
}
layer {
  name: "345"
  type: "Convolution"
  bottom: "344"
  top: "345"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "346"
  type: "ReLU"
  bottom: "345"
  top: "346"
}
layer {
  name: "347"
  type: "Convolution"
  bottom: "346"
  top: "347"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "348"
  type: "Convolution"
  bottom: "346"
  top: "348"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "349"
  type: "Convolution"
  bottom: "347"
  top: "349"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "350"
  type: "Eltwise"
  bottom: "230"
  bottom: "348"
  top: "350"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "351"
  type: "Eltwise"
  bottom: "350"
  bottom: "349"
  top: "351"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "352"
  type: "Convolution"
  bottom: "351"
  top: "352"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "353"
  type: "ReLU"
  bottom: "352"
  top: "353"
}
layer {
  name: "354"
  type: "Convolution"
  bottom: "353"
  top: "354"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "355"
  type: "ReLU"
  bottom: "354"
  top: "355"
}
layer {
  name: "356"
  type: "Convolution"
  bottom: "355"
  top: "356"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "357"
  type: "Eltwise"
  bottom: "356"
  bottom: "351"
  top: "357"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "358"
  type: "ReLU"
  bottom: "357"
  top: "358"
}
layer {
  name: "359"
  type: "Pooling"
  bottom: "351"
  top: "359"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "360"
  type: "Convolution"
  bottom: "359"
  top: "360"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "361"
  type: "ReLU"
  bottom: "360"
  top: "361"
}
layer {
  name: "362"
  type: "Convolution"
  bottom: "361"
  top: "362"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "363"
  type: "ReLU"
  bottom: "362"
  top: "363"
}
layer {
  name: "364"
  type: "Convolution"
  bottom: "363"
  top: "364"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "365"
  type: "Eltwise"
  bottom: "364"
  bottom: "359"
  top: "365"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "366"
  type: "ReLU"
  bottom: "365"
  top: "366"
}
layer {
  name: "367"
  type: "Convolution"
  bottom: "366"
  top: "367"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "368"
  type: "ReLU"
  bottom: "367"
  top: "368"
}
layer {
  name: "369"
  type: "Convolution"
  bottom: "368"
  top: "369"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "370"
  type: "ReLU"
  bottom: "369"
  top: "370"
}
layer {
  name: "371"
  type: "Convolution"
  bottom: "370"
  top: "371"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "372"
  type: "Eltwise"
  bottom: "371"
  bottom: "366"
  top: "372"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "373"
  type: "ReLU"
  bottom: "372"
  top: "373"
}
layer {
  name: "374"
  type: "Pooling"
  bottom: "366"
  top: "374"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "375"
  type: "Convolution"
  bottom: "374"
  top: "375"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "376"
  type: "ReLU"
  bottom: "375"
  top: "376"
}
layer {
  name: "377"
  type: "Convolution"
  bottom: "376"
  top: "377"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "378"
  type: "ReLU"
  bottom: "377"
  top: "378"
}
layer {
  name: "379"
  type: "Convolution"
  bottom: "378"
  top: "379"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "380"
  type: "Eltwise"
  bottom: "379"
  bottom: "374"
  top: "380"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "381"
  type: "ReLU"
  bottom: "380"
  top: "381"
}
layer {
  name: "382"
  type: "Convolution"
  bottom: "381"
  top: "382"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "383"
  type: "ReLU"
  bottom: "382"
  top: "383"
}
layer {
  name: "384"
  type: "Convolution"
  bottom: "383"
  top: "384"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "385"
  type: "ReLU"
  bottom: "384"
  top: "385"
}
layer {
  name: "386"
  type: "Convolution"
  bottom: "385"
  top: "386"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "387"
  type: "Eltwise"
  bottom: "386"
  bottom: "381"
  top: "387"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "388"
  type: "ReLU"
  bottom: "387"
  top: "388"
}
layer {
  name: "389"
  type: "Pooling"
  bottom: "381"
  top: "389"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "390"
  type: "Convolution"
  bottom: "389"
  top: "390"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "391"
  type: "ReLU"
  bottom: "390"
  top: "391"
}
layer {
  name: "392"
  type: "Convolution"
  bottom: "391"
  top: "392"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "393"
  type: "ReLU"
  bottom: "392"
  top: "393"
}
layer {
  name: "394"
  type: "Convolution"
  bottom: "393"
  top: "394"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "395"
  type: "Eltwise"
  bottom: "394"
  bottom: "389"
  top: "395"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "396"
  type: "ReLU"
  bottom: "395"
  top: "396"
}
layer {
  name: "397"
  type: "Convolution"
  bottom: "396"
  top: "397"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "398"
  type: "ReLU"
  bottom: "397"
  top: "398"
}
layer {
  name: "399"
  type: "Convolution"
  bottom: "398"
  top: "399"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "400"
  type: "ReLU"
  bottom: "399"
  top: "400"
}
layer {
  name: "401"
  type: "Convolution"
  bottom: "400"
  top: "401"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "402"
  type: "Eltwise"
  bottom: "401"
  bottom: "396"
  top: "402"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "403"
  type: "ReLU"
  bottom: "402"
  top: "403"
}
layer {
  name: "404"
  type: "Pooling"
  bottom: "396"
  top: "404"
  pooling_param {
    pool: MAX
    kernel_h: 2
    kernel_w: 2
    stride_h: 2
    stride_w: 2
    pad_h: 0
    pad_w: 0
  }
}
layer {
  name: "405"
  type: "Convolution"
  bottom: "404"
  top: "405"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "406"
  type: "ReLU"
  bottom: "405"
  top: "406"
}
layer {
  name: "407"
  type: "Convolution"
  bottom: "406"
  top: "407"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "408"
  type: "ReLU"
  bottom: "407"
  top: "408"
}
layer {
  name: "409"
  type: "Convolution"
  bottom: "408"
  top: "409"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "410"
  type: "Eltwise"
  bottom: "409"
  bottom: "404"
  top: "410"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "411"
  type: "ReLU"
  bottom: "410"
  top: "411"
}
layer {
  name: "412"
  type: "Convolution"
  bottom: "411"
  top: "412"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "413"
  type: "ReLU"
  bottom: "412"
  top: "413"
}
layer {
  name: "414"
  type: "Convolution"
  bottom: "413"
  top: "414"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "415"
  type: "ReLU"
  bottom: "414"
  top: "415"
}
layer {
  name: "416"
  type: "Convolution"
  bottom: "415"
  top: "416"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "417"
  type: "Eltwise"
  bottom: "416"
  bottom: "411"
  top: "417"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "418"
  type: "ReLU"
  bottom: "417"
  top: "418"
}
layer {
  name: "419"
  type: "Convolution"
  bottom: "418"
  top: "419"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "420"
  type: "ReLU"
  bottom: "419"
  top: "420"
}
layer {
  name: "421"
  type: "Convolution"
  bottom: "420"
  top: "421"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "422"
  type: "ReLU"
  bottom: "421"
  top: "422"
}
layer {
  name: "423"
  type: "Convolution"
  bottom: "422"
  top: "423"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "424"
  type: "Eltwise"
  bottom: "423"
  bottom: "418"
  top: "424"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "425"
  type: "ReLU"
  bottom: "424"
  top: "425"
}
layer {
  name: "427"
  type: "Deconvolution"
  bottom: "425"
  top: "427"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 2
    group: 256
    stride: 2
  }
}
layer {
  name: "428"
  type: "Eltwise"
  bottom: "403"
  bottom: "427"
  top: "428"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "429"
  type: "Convolution"
  bottom: "428"
  top: "429"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "430"
  type: "ReLU"
  bottom: "429"
  top: "430"
}
layer {
  name: "431"
  type: "Convolution"
  bottom: "430"
  top: "431"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "432"
  type: "ReLU"
  bottom: "431"
  top: "432"
}
layer {
  name: "433"
  type: "Convolution"
  bottom: "432"
  top: "433"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "434"
  type: "Eltwise"
  bottom: "433"
  bottom: "428"
  top: "434"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "435"
  type: "ReLU"
  bottom: "434"
  top: "435"
}
layer {
  name: "437"
  type: "Deconvolution"
  bottom: "435"
  top: "437"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 2
    group: 256
    stride: 2
  }
}
layer {
  name: "438"
  type: "Eltwise"
  bottom: "388"
  bottom: "437"
  top: "438"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "439"
  type: "Convolution"
  bottom: "438"
  top: "439"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "440"
  type: "ReLU"
  bottom: "439"
  top: "440"
}
layer {
  name: "441"
  type: "Convolution"
  bottom: "440"
  top: "441"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "442"
  type: "ReLU"
  bottom: "441"
  top: "442"
}
layer {
  name: "443"
  type: "Convolution"
  bottom: "442"
  top: "443"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "444"
  type: "Eltwise"
  bottom: "443"
  bottom: "438"
  top: "444"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "445"
  type: "ReLU"
  bottom: "444"
  top: "445"
}
layer {
  name: "447"
  type: "Deconvolution"
  bottom: "445"
  top: "447"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 2
    group: 256
    stride: 2
  }
}
layer {
  name: "448"
  type: "Eltwise"
  bottom: "373"
  bottom: "447"
  top: "448"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "449"
  type: "Convolution"
  bottom: "448"
  top: "449"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "450"
  type: "ReLU"
  bottom: "449"
  top: "450"
}
layer {
  name: "451"
  type: "Convolution"
  bottom: "450"
  top: "451"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "452"
  type: "ReLU"
  bottom: "451"
  top: "452"
}
layer {
  name: "453"
  type: "Convolution"
  bottom: "452"
  top: "453"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "454"
  type: "Eltwise"
  bottom: "453"
  bottom: "448"
  top: "454"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "455"
  type: "ReLU"
  bottom: "454"
  top: "455"
}
layer {
  name: "457"
  type: "Deconvolution"
  bottom: "455"
  top: "457"
  convolution_param {
    num_output: 256
    bias_term: false
    kernel_size: 2
    group: 256
    stride: 2
  }
}
layer {
  name: "458"
  type: "Eltwise"
  bottom: "358"
  bottom: "457"
  top: "458"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "459"
  type: "Convolution"
  bottom: "458"
  top: "459"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "460"
  type: "ReLU"
  bottom: "459"
  top: "460"
}
layer {
  name: "461"
  type: "Convolution"
  bottom: "460"
  top: "461"
  convolution_param {
    num_output: 128
    bias_term: true
    group: 128
    pad_h: 1
    pad_w: 1
    kernel_h: 3
    kernel_w: 3
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "462"
  type: "ReLU"
  bottom: "461"
  top: "462"
}
layer {
  name: "463"
  type: "Convolution"
  bottom: "462"
  top: "463"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "464"
  type: "Eltwise"
  bottom: "463"
  bottom: "458"
  top: "464"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "465"
  type: "ReLU"
  bottom: "464"
  top: "465"
}
layer {
  name: "466"
  type: "Convolution"
  bottom: "465"
  top: "466"
  convolution_param {
    num_output: 256
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}
layer {
  name: "467"
  type: "ReLU"
  bottom: "466"
  top: "467"
}
layer {
  name: "468"
  type: "Convolution"
  bottom: "467"
  top: "468"
  convolution_param {
    num_output: 16
    bias_term: true
    group: 1
    pad_h: 0
    pad_w: 0
    kernel_h: 1
    kernel_w: 1
    stride_h: 1
    stride_w: 1
    dilation: 1
  }
}

